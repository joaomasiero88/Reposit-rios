{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explainable AI = XAI\n",
    "\n",
    "João A. Masiero 06/02/23\n",
    "\n",
    "- Shapley values, importância das variáveis na modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from numpy import sqrt, log, exp, pi\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier, BernoulliRBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import mean, absolute\n",
    "import yfinance as yf\n",
    "\n",
    "from datetime import datetime, timedelta  \n",
    "\n",
    "from statsmodels.tsa.stattools import pacf, acf\n",
    "\n",
    "from numpy_ext import rolling_apply as rolling_apply_ext\n",
    "\n",
    "import pyfolio as pf\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"darkgrid\", context = \"talk\", palette = \"rainbow\")\n",
    "import shap # v0.39.0\n",
    "shap.initjs()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "\n",
    "#Janela temporal#\n",
    "inicio = \"01-01-2013\"\n",
    "fim = \"01-01-2023\"\n",
    "\n",
    "ticker1 = \"CCMFUT\" \n",
    "df0 = pd.read_excel(\"CCM_Historico.xlsx\", names=[\"Date\", \"Open\", \"High\", \"Low\", \"Adj Close\"]).set_index(\"Date\")\n",
    "df0 = df0.replace({',': '.'}, regex=True) #substitui \",\" por \".\"\n",
    "df1 = df0.loc[inicio:fim].sort_index(ascending=True).astype(float)\n",
    "df1[\"Returns\"] = df1[\"Adj Close\"].pct_change(1)\n",
    "df1[\"Vol\"] = df1[\"Returns\"].rolling(20).std()*np.sqrt(252)\n",
    "df1.dropna(axis = 0, inplace = True) \n",
    "\n",
    "#Funções úteis\n",
    "\n",
    "def get_acf1(x):\n",
    "    return acf(x, alpha = 0.05, nlags = 5)[0][1]\n",
    "\n",
    "def zscore(x):\n",
    "    return ((x - x.mean())/np.std(x))[-1]\n",
    "\n",
    "def next_business_day(date):\n",
    "    if isinstance(date, str):\n",
    "        date = pd.to_datetime(date)\n",
    "    business_days = pd.date_range(start=date, end=date + pd.DateOffset(weeks=1), freq='B')\n",
    "    return business_days.min()\n",
    "\n",
    "# Variáveis - simples, mas funcionais\n",
    "\n",
    "df1[\"f1\"] = rolling_apply_ext(get_acf1, 20, df1[\"Returns\"])\n",
    "df1[\"f2\"] = rolling_apply_ext(zscore, 10, df1[\"Returns\"])\n",
    "\n",
    "df1[\"MA5\"] = df1[\"Adj Close\"].rolling(5).mean()\n",
    "df1[\"MA10\"] = df1[\"Adj Close\"].rolling(10).mean()\n",
    "df1[\"MA20\"] = df1[\"Adj Close\"].rolling(20).mean()\n",
    "df1[\"MA52\"] = df1[\"Adj Close\"].rolling(52).mean()\n",
    "\n",
    "df1[\"f3\"] = df1[\"Adj Close\"]/df1[\"MA5\"]-1\n",
    "df1[\"f4\"] = df1[\"Adj Close\"]/df1[\"MA10\"]-1\n",
    "df1[\"f5\"] = df1[\"Adj Close\"]/df1[\"MA20\"]-1\n",
    "df1[\"f6\"] = df1[\"Adj Close\"]/df1[\"MA52\"]-1\n",
    "\n",
    "df1[\"f7\"] = df1[\"Returns\"].rolling(5).std()\n",
    "df1[\"f8\"] = df1[\"Returns\"].rolling(10).std()\n",
    "df1[\"f9\"] = df1[\"Returns\"].rolling(20).std()\n",
    "df1[\"f10\"] = df1[\"Returns\"].rolling(52).std()\n",
    "\n",
    "df1[\"f11\"] = df1[\"Returns\"].shift(1)\n",
    "df1[\"f12\"] = df1[\"Returns\"].shift(2)\n",
    "df1[\"f13\"] = df1[\"Returns\"].shift(3)\n",
    "df1[\"f14\"] = df1[\"Returns\"].shift(4)\n",
    "df1[\"f15\"] = df1[\"Returns\"].shift(5)\n",
    "df1[\"f16\"] = df1[\"Returns\"].shift(6)\n",
    "df1[\"f17\"] = df1[\"Returns\"].shift(7)\n",
    "df1[\"f18\"] = df1[\"Returns\"].shift(8)\n",
    "df1[\"f19\"] = df1[\"Returns\"].shift(9)\n",
    "df1[\"f20\"] = df1[\"Returns\"].shift(10)\n",
    "\n",
    "df1[\"f21\"] = np.where(df1[\"Vol\"] < 0.15, 1\n",
    "                     , np.where(df1[\"Vol\"] > 0.20, -1, 0))\n",
    "\n",
    "previsao = df1.iloc[-6:].copy()\n",
    "ultima = df1[\"Adj Close\"].iloc[-6:-5]\n",
    "today = df1[\"Adj Close\"][-1]\n",
    "#print(df1.tail())\n",
    "\n",
    "# Construção do alvo\n",
    "p = 5\n",
    "# Alvo 1 - Volatilidade em 5 dias para frente\n",
    "df1[\"Alvo1\"] = df1[\"Adj Close\"].shift(-p)\n",
    "df1[\"Alvo2\"] = np.where(df1[\"Alvo1\"] > df1[\"Adj Close\"], 1, 0)\n",
    "df1[\"Alvo3\"] = df1[\"Adj Close\"].pct_change(p).shift(-p)\n",
    "\n",
    "df1.dropna(inplace = True)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados com as variaveis em x e o alvo em y\n",
    "\n",
    "# Separando os dados entre treinamento e teste\n",
    "\n",
    "# Vamos treinar com 5 anos\n",
    "start_train = \"2014-01-01\"\n",
    "end_train = \"2018-12-31\"\n",
    "\n",
    "# Vamos testar com 4 anos\n",
    "start_test = \"2019-01-01\"\n",
    "end_test = \"2023-12-31\"\n",
    "\n",
    "df1_train = df1.loc[start_train : end_train]\n",
    "\n",
    "df1_test = df1.loc[start_test : end_test]\n",
    "\n",
    "\n",
    "# Separando os dados com as variaveis em x e o alvo em y\n",
    " \n",
    "manter = [\"f3\", \"f4\", \"f5\", \"f6\", \"f8\", \"f10\"\n",
    "          , \"f12\", \"f13\", \"f14\", \"f16\", \"f17\", \"f18\", \"f20\"\n",
    "          , \"f19\"\n",
    "          , \"f21\"\n",
    "          , \"f1\", \"f2\", \"Returns\"\n",
    "         ]\n",
    "\n",
    "x_train = df1_train[manter]\n",
    "y_train = df1_train[\"Alvo2\"]\n",
    "\n",
    "x_test = df1_test[manter]\n",
    "y_test = df1_test[\"Alvo2\"]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes = (10, 100), max_iter = 2000\n",
    "                     , solver = \"adam\", verbose = 10, tol = 1e-8, random_state = 42\n",
    "                     , learning_rate_init = .001 , alpha = .0001\n",
    "                     , activation = \"relu\"\n",
    "                     , epsilon = 1e-9\n",
    "                    )\n",
    "\n",
    "model.fit(x_train, y_train) # essa é a linha que treina o modelo!!!!\n",
    "\n",
    "#pickle.dump(model, open(\"/Users/leandroguerra/Library/CloudStorage/OneDrive-Personale/OM Quant Services/lab-of-ideas/vol-forecasting.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation - no cut-off\n",
    "y_pred_test = model.predict(x_test)\n",
    "df1[\"pred\"] = model.predict(df1[manter])\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custo_op = 0.001\n",
    "\n",
    "df1.loc[: , \"Model_Return\"] = np.where(((df1.loc[: , \"pred\"] == 1) & (df1.loc[: , \"Vol\"] < 0.15))\n",
    "                                       , df1[\"Alvo3\"] - custo_op\n",
    "                                       ,  np.where(((df1.loc[: , \"pred\"] == 0) & (df1.loc[: , \"Vol\"] > 0.25))\n",
    "                                       , -df1[\"Alvo3\"] - custo_op, 0))\n",
    "\n",
    "df1.loc[: , \"Model_Return_Acc\"] = df1[\"Model_Return\"].cumsum()*100\n",
    "\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 1\n",
    "                    , shared_xaxes = True\n",
    "                    , vertical_spacing = 0.05)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = df1.index, y = df1[\"Model_Return_Acc\"]\n",
    "                                , name = \"OM Model\"\n",
    "                                , line = dict(color = \"blue\"))\n",
    "              , row = 1, col = 1)\n",
    "\n",
    "\n",
    "\n",
    "fig.add_vline(x = end_train, line_width = 3, line_dash=\"dash\", line_color = \"black\")\n",
    "\n",
    "fig.update_layout(height = 600, width = 800\n",
    "                  , title_text = \"Forecasting \" + ticker1 + \" - Accumulated Returns\"\n",
    "                  , font_color = \"blue\"\n",
    "                  , title_font_color = \"black\"\n",
    "                  , xaxis_title = \"Time\"\n",
    "                  , yaxis_title = \"Accumulated returns (%)\"\n",
    "                  , font = dict(size = 15, color = \"Black\")\n",
    "                 )\n",
    "\n",
    "fig.update_layout(hovermode = \"x unified\")\n",
    "\n",
    "# Code to exclude empty dates from the chart\n",
    "dt_all = pd.date_range(start = df1.index[0]\n",
    "                       , end = df1.index[-1]\n",
    "                       , freq = \"D\")\n",
    "dt_all_py = [d.to_pydatetime() for d in dt_all]\n",
    "dt_obs_py = [d.to_pydatetime() for d in df1.index]\n",
    "\n",
    "dt_breaks = [d for d in dt_all_py if d not in dt_obs_py]\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangebreaks = [dict(values = dt_breaks)]\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2.index.name = \"Data\"\n",
    "df2.reset_index(inplace = True)\n",
    "\n",
    "df2[\"Data\"] = pd.to_datetime(df2[\"Data\"])\n",
    "\n",
    "df2[\"train_test\"] = np.where(df2[\"Data\"] > end_train, 1, -1)\n",
    "\n",
    "base_agregada = df2.resample(\"D\", on = \"Data\").sum()\n",
    "\n",
    "base_agregada.loc[: , \"Model_Return_Acc\"] = base_agregada[\"Model_Return\"].cumsum()*100\n",
    "\n",
    "summary = df2.copy()\n",
    "summary[\"Data\"] = pd.to_datetime(summary[\"Data\"], format = \"%Y-%m\")\n",
    "\n",
    "summary = summary.groupby([summary[\"Data\"].dt.year]).agg({\"Model_Return\": sum})\n",
    "\n",
    "summary.index = summary.index.set_names([\"Ano\"])\n",
    "\n",
    "summary*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Results\n",
    "\n",
    "resultados = pd.DataFrame({'Real': y_test, 'Previsto': y_pred_test})\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Last measured value before a prediction on the day \" + str(previsao.index[0].strftime(\"%Y-%m-%d\")))\n",
    "print(\"%.2f\" % ultima)\n",
    "print(\"Predicted move for \" + ticker1 + \" on that day was\")\n",
    "if (model.predict(previsao[manter].iloc[-6:-5].values.reshape(1, -1))[0] == 0) & (ultima > 30).values[0]:\n",
    "    print(\"Down\")\n",
    "elif (model.predict(previsao[manter].iloc[-6:-5].values.reshape(1, -1))[0] == 0) & (ultima < 30).values[0]:\n",
    "    print(\"Do nothing\")\n",
    "else:\n",
    "    print(\"Buy\")\n",
    "    \n",
    "print(\"Value today \" + str(datetime.today().strftime(\"%Y-%m-%d\")))\n",
    "print(\"%.2f\" % today)\n",
    "print(\"\")\n",
    "print(\"#\"*70)\n",
    "print(\"Next prediction for \" + ticker1 + \" on the day \" + str(next_business_day((datetime.today() + timedelta(days = 5))).strftime(\"%Y-%m-%d\")))\n",
    "if (model.predict(previsao[manter].iloc[-1].values.reshape(1, -1))[0] == 0) & (today > 30):\n",
    "    print(\"Down\")\n",
    "elif (model.predict(previsao[manter].iloc[-1].values.reshape(1, -1))[0] == 0) & (today < 30):\n",
    "    print(\"Do nothing\")\n",
    "else:\n",
    "    print(\"Buy\")\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_returns = df1.loc[start_test : end_test][\"Model_Return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "pf.plot_drawdown_underwater(bt_returns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest Evaluation functions\n",
    "\n",
    "def rolling_sharpe(returns, window):\n",
    "    \"\"\"\n",
    "    Calculates the rolling Sharpe ratio for a given dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        - returns: a pandas Series or DataFrame of returns\n",
    "        - window: the number of periods to use in the rolling window calculation\n",
    "        \n",
    "    Returns:\n",
    "        - a pandas Series or DataFrame of the rolling Sharpe ratio\n",
    "    \"\"\"\n",
    "    # calculate the mean return\n",
    "    mean_return = returns.rolling(window=window).mean()\n",
    "    # calculate the standard deviation of returns\n",
    "    std_return = returns.rolling(window=window).std()\n",
    "    # calculate the sharpe ratio\n",
    "    sharpe_ratio = mean_return / std_return\n",
    "    return sharpe_ratio.dropna()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def rolling_volatility(returns, window):\n",
    "    \"\"\"\n",
    "    Calculates the rolling volatility of returns for a given dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        - returns: a pandas Series or DataFrame of returns\n",
    "        - window: the number of periods to use in the rolling window calculation\n",
    "        \n",
    "    Returns:\n",
    "        - a pandas Series or DataFrame of the rolling volatility of returns\n",
    "    \"\"\"\n",
    "    # calculate the standard deviation of returns\n",
    "    rolling_std = returns.rolling(window=window).std()\n",
    "    return rolling_std.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sr = rolling_sharpe(bt_returns, 180)\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 1\n",
    "                    , shared_xaxes = True\n",
    "                    , vertical_spacing = 0.05)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = r_sr.index, y = r_sr\n",
    "                                , name = \"OM Model\"\n",
    "                                , line = dict(color = \"blue\"))\n",
    "              , row = 1, col = 1)\n",
    "\n",
    "fig.add_hline(y = r_sr.mean(), line_width = 3, line_dash=\"dash\", line_color = \"black\")\n",
    "\n",
    "fig.update_layout(height = 600, width = 800\n",
    "                  , title_text = \"Vol Forecasting - Rolling Sharpe Ratio (6 months)\"\n",
    "                  , font_color = \"blue\"\n",
    "                  , title_font_color = \"black\"\n",
    "                  , xaxis_title = \"Time\"\n",
    "                  , yaxis_title = \"Sharpe Ratio\"\n",
    "                  , font = dict(size = 15, color = \"Black\")\n",
    "                 )\n",
    "\n",
    "fig.update_layout(hovermode = \"x unified\")\n",
    "\n",
    "# Code to exclude empty dates from the chart\n",
    "dt_all = pd.date_range(start = resultados.index[0]\n",
    "                       , end = resultados.index[-1]\n",
    "                       , freq = \"D\")\n",
    "dt_all_py = [d.to_pydatetime() for d in dt_all]\n",
    "dt_obs_py = [d.to_pydatetime() for d in resultados.index]\n",
    "\n",
    "dt_breaks = [d for d in dt_all_py if d not in dt_obs_py]\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangebreaks = [dict(values = dt_breaks)]\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vol = rolling_volatility(bt_returns, 180)*100\n",
    "fig = make_subplots(rows = 1, cols = 1\n",
    "                    , shared_xaxes = True\n",
    "                    , vertical_spacing = 0.05)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = r_vol.index, y = r_vol\n",
    "                                , name = \"OM Model\"\n",
    "                                , line = dict(color = \"blue\"))\n",
    "              , row = 1, col = 1)\n",
    "\n",
    "fig.add_hline(y = r_vol.mean(), line_width = 3, line_dash=\"dash\", line_color = \"black\")\n",
    "\n",
    "fig.update_layout(height = 600, width = 800\n",
    "                  , title_text = \"Vol Forecasting - Rolling Volatility (6 months)\"\n",
    "                  , font_color = \"blue\"\n",
    "                  , title_font_color = \"black\"\n",
    "                  , xaxis_title = \"Time\"\n",
    "                  , yaxis_title = \"Volatility\"\n",
    "                  , font = dict(size = 15, color = \"Black\")\n",
    "                 )\n",
    "\n",
    "fig.update_layout(hovermode = \"x unified\")\n",
    "\n",
    "# Code to exclude empty dates from the chart\n",
    "dt_all = pd.date_range(start = resultados.index[0]\n",
    "                       , end = resultados.index[-1]\n",
    "                       , freq = \"D\")\n",
    "dt_all_py = [d.to_pydatetime() for d in dt_all]\n",
    "dt_obs_py = [d.to_pydatetime() for d in resultados.index]\n",
    "\n",
    "dt_breaks = [d for d in dt_all_py if d not in dt_obs_py]\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangebreaks = [dict(values = dt_breaks)]\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, x_test)\n",
    "shap_test = explainer(x_test)\n",
    "print(f\"Shap values length: {len(shap_test)}\\n\")\n",
    "print(f\"Sample shap value:\\n{shap_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average target value (training data): {y_train.mean():.2f}\")\n",
    "print(f\"Base value: {np.unique(shap_test.base_values)[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame(shap_test.values, \n",
    "                       columns=shap_test.feature_names, \n",
    "                       index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations to understand the feature contribution\n",
    "columns = shap_df.apply(np.abs).mean()\\\n",
    "                 .sort_values(ascending=False).index\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "sns.barplot(data=shap_df[columns].apply(np.abs), orient='h', \n",
    "            ax=ax[0])\n",
    "ax[0].set_title(\"Mean absolute shap value\")\n",
    "sns.boxplot(data=shap_df[columns], orient='h', ax=ax[1])\n",
    "ax[1].set_title(\"Distribution of shap values\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trade = np.where(shap_df.index.isin([df1.loc[start_test : end_test][[\"Model_Return\"]].idxmax().values[0]]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_trade = np.where(shap_df.index.isin([df1.loc[start_test : end_test][[\"Model_Return\"]].idxmin().values[0]]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for understanding predictions for individual cases\n",
    "shap.plots.bar(shap_test[max_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for understanding predictions for individual cases\n",
    "shap.plots.bar(shap_test[min_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterfallData():\n",
    "    def __init__ (self, shap_test, index):\n",
    "        self.values = shap_test[index].values\n",
    "        self.base_values = shap_test[index].base_values[0]\n",
    "        self.data = shap_test[index].data\n",
    "        self.feature_names = shap_test.feature_names\n",
    "shap.plots.waterfall(shap_test[max_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterfallData():\n",
    "    def __init__ (self, shap_test, index):\n",
    "        self.values = shap_test[index].values\n",
    "        self.base_values = shap_test[index].base_values[0]\n",
    "        self.data = shap_test[index].data\n",
    "        self.feature_names = shap_test.feature_names\n",
    "shap.plots.waterfall(shap_test[min_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(shap_test[max_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(shap_test[min_trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d085d2508a1aa4d1a3cff6aaaa3bf934685ce8bc1145bc78ff1cb32b428d0398"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
